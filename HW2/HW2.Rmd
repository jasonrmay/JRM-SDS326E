---
title: "HW2"
output: html_document
---

```{r}
library(tidyverse)
library(ggrepel)
```

# Question 8.A
```{r}
# load the data
dat <- read_csv("Data/Auto.csv")
glimpse(dat)

# filter out the rows with "?" in the horsepower column and convert it to numeric data type.
dat <- dat |> filter(horsepower != "?") |> mutate(horsepower = as.numeric(horsepower))

model <- lm(mpg ~ horsepower, data = dat)
summary(model)

horsepower_value <- data.frame(horsepower = 98)
predicted_mpg <- predict(model, horsepower_value, interval = "confidence", level = 0.95)
print(paste("predicted mpg for a car with a horsepower of 98: ", predicted_mpg[1]))
print(paste("95% confidence interval for the mean mpg:", predicted_mpg[2], "to", predicted_mpg[3]))
predicted_mpg <- predict(model, horsepower_value, interval = "prediction", level = 0.95)
print(paste("95% prediction interval for the mpg of a car with 98 horsepower:", predicted_mpg[2], "to", predicted_mpg[3]))
```

*i. There is a significant relationship between horsepower and miles per gallon (mpg) since the p-value for the horsepower coefficient is less than 0.05. The negative coefficient indicates that as horsepower increases, mpg tends to decrease.*

*ii. There is a weak relationship between horsepower and miles per gallon (mpg) as the estimated correlation coefficient is less than 0.3.*

*iii. The negative estimate indicates that the relationship between horsepower and mpg is negative, meaning that as horsepower increases, mpg tends to decrease.*

*iv. For a car with a horsepower of 98, the predicted mpg is 24.467 with a 95% confidence interval of 23.973 to 24.961 mpg. The prediction interval is 14.809 to 34.125 mpg.*

# Question 8.B

```{r}
dat |> 
  ggplot() + 
  geom_point(aes(x = horsepower, y = mpg)) + 
  geom_abline(intercept = model$coefficients[1], slope = model$coefficients[2], color = "red") +
  labs(title = "Scatter plot of Horsepower vs. Miles Per Gallon",
       x = "Horsepower",
       y = "Miles Per Gallon")
```
The scatter plot shows a negative relationship between horsepower and miles per gallon (mpg). As horsepower increases, mpg tends to decrease. The red line represents the fitted regression line, which also indicates a negative slope. This visual representation supports the conclusion from the regression analysis that there is a negative relationship between horsepower and mpg.

# Question 8.C
```{r}
plot(model)
```
The residual vs fitted plot shows the residuals to be funneling and have a parabolic shape . This indicates that the variance of the residuals is not constant and that there may be a non-linear relationship between horsepower and miles per gallon. Therefore, this model fails to satisfy the homoscedasticity assumption and the linear residual assumption.

# Question 9.A
```{r}
dat <- read_csv("Data/Auto.csv")
glimpse(dat)

# filter out the rows with "?" in the horsepower column and convert it to numeric data type.
dat <- dat |> filter(horsepower != "?") |> mutate(horsepower = as.numeric(horsepower))

pairs(dat[, 1:8])
```

# Question 9.B
```{r}
cor(dat[, 1:8])
```

# Question 9.C
```{r}
# run a linear regression model with all the predictors
predictors = dat[, 1:8]
model <- lm(mpg ~ ., data = predictors)
summary(model)
```

# Question 9.D
```{r}
plot(model)
```

# Question 9.E
```{r}
# Use the * and : symbols to fit linear regression models with interaction effects. 
model <- lm(mpg ~ cylinders * displacement * horsepower * weight * acceleration * year, data = predictors)
summary(model)
```

# Question 9.F
```{r}
log_data <- lapply(dat[, 1:8], log)
sqrt_data <- lapply(dat[, 1:8], sqrt)
squared_data <- lapply(dat[, 1:8], function(x) x^2)

log_model <- lm(mpg ~ ., data = log_data)
sqrt_model <- lm(mpg ~ ., data = sqrt_data)
squared_model <- lm(mpg ~ ., data = squared_data)

summary(log_model)
summary(sqrt_model)
summary(squared_model)

```


# Question 10 Data Cleaning
```{r}
dat <- read_csv("Data/Carseats.csv")
head(dat)
tail(dat)
sample(dat, 10)
```
# Question 10.A
```{r}
model <- lm(Sales ~ Price + Urban + US, data = dat)
summary(model)
```
# Question 10.B
```{r}

```

# Question 10.C
```{r}

```

# Question 10.D
```{r}

```

# Question 10.E
```{r}
sig_model <- lm (Sales ~ Price, data = dat)
summary(sig_model)
```

# Question 10.F
```{r}

```

# Question 10.G
```{r}
confidence_int <- confint(sig_model)
```

# Question 10.H
```{r}
plot(sig_model)
```


# Question 13.A
```{r}
set.seed(1)
x <- rnorm(100)
```

# Question 13.B
```{r}
eps <- rnorm(100, sd = 0.25)
```

# Question 13.C
```{r}
y <- -1 + 0.5 * x + eps
```

# Question 13.D
```{r}
ggplot() +
geom_point(aes(x = x, y = y)) +
theme_bw()
```

# Question 13.E
```{r}
model <- lm(y ~ x)
summary(model)
```

# Question 13.F
```{r}
ggplot() +
geom_point(aes(x = x, y = y)) +
geom_abline(intercept = model$coefficients[1], slope = model$coefficients[2], color = "BLUE", linetype = "dashed") +
geom_abline(intercept = -1, slope = 0.5) +
geom_label_repel(aes(x = 0, y = -1, label = "True Relation"), color = "red", nudge_y = 0.8, nudge_x = -.1) +
geom_label_repel(aes(x = 0, y = -1, label = "LSRL"), color = "blue", nudge_y = -0.8, nudge_x = .1) +
theme_bw()
```

# Question 13.G
```{r}
quadratic_model <- lm(y ~ x + I(x^2))
summary(quadratic_model)
MSE_quadratic <- mean(quadratic_model$residuals^2)
print(paste("MSE of the quadratic model: ", MSE_quadratic))
```

# Question 13.H
```{r}
x <- rnorm(100)
eps <- rnorm(100, sd = 0.125)
y <- -1 + 0.5 * x + eps
less_noise_model <- lm(y ~ x)
summary(less_noise_model)

ggplot() +
geom_point(aes(x = x, y = y)) +
geom_abline(intercept = less_noise_model$coefficients[1], slope = less_noise_model$coefficients[2], color = "BLUE", linetype = "dashed") +
geom_abline(intercept = -1, slope = 0.5) +
geom_label_repel(aes(x = 0, y = -1, label = "True Relation"), color = "red", nudge_y = 0.8, nudge_x = -.1) +
geom_label_repel(aes(x = 0, y = -1, label = "LSRL"), color = "blue", nudge_y = -0.8, nudge_x = .1) +
theme_bw()
```

# Question 13.I
```{r}
x <- rnorm(100)
eps <- rnorm(100, sd = 0.5)
y <- -1 + 0.5 * x + eps
more_noise_model <- lm(y ~ x)
summary(more_noise_model)

ggplot() +
geom_point(aes(x = x, y = y)) +
geom_abline(intercept = more_noise_model$coefficients[1], slope = more_noise_model$coefficients[2], color = "BLUE", linetype = "dashed") +
geom_abline(intercept = -1, slope = 0.5) +
geom_label_repel(aes(x = 0, y = -1, label = "True Relation"), color = "red", nudge_y = 0.8, nudge_x = -.1) +
geom_label_repel(aes(x = 0, y = -1, label = "LSRL"), color = "blue", nudge_y = -0.8, nudge_x = .1) +
theme_bw()
```

# Question 13.J
```{r}
less_CI <- confint(less_noise_model)
CI <- confint(model)
more_CI <- confint(more_noise_model)
```

# (Bonus) Question 11
```{r}

```

